'''
This script proceesses the data generated by Fenics. It reads the h5
and xdmf files and converts them to npz, which is used by the mdbench.
'''

import argparse
from pathlib import Path

import h5py
import numpy as np
import xml.etree.ElementTree as ET

def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser()
    parser.add_argument("--h5_dir", type=str, required=True, help="Path to directory containing the h5 files")
    parser.add_argument("--output_dir", type=str, required=True, help="Path to directory to save the npz files")
    return parser.parse_args()

def process_heat_soil(h5_file: Path, xdmf_file: Path, output_path: Path):
    observations = []
    with h5py.File(h5_file, 'r') as f:
        grid = f['Mesh']['0']['mesh']['geometry'][:]
        for key in sorted(f['VisualisationVector'].keys(), key=int):
            observations.append(f['VisualisationVector'][key][:])
        observations = np.array(observations)

    spatial_dim = 1 if '1d' in h5_file.stem else 2 if '2d' in h5_file.stem else 3
    if spatial_dim == 1:
        x_coord = sorted(set(grid[:, 0]))
        observations = observations.transpose(1, 0, 2)
    elif spatial_dim == 2:
        x_coord = sorted(set(grid[:, 0]))
        y_coord = sorted(set(grid[:, 1]))
        observations = observations.reshape(-1, len(y_coord), len(x_coord), 1)
        # (Nt, Ny, Nx, 1) -> (Nx, Ny, Nt, 1)
        observations = observations.transpose(2, 1, 0, 3)
    elif spatial_dim == 3:
        x_coord = sorted(set(grid[:, 0]))
        y_coord = sorted(set(grid[:, 1]))
        z_coord = sorted(set(grid[:, 2]))
        # TODO: these need to be checked
        observations = observations.reshape(-1, len(x_coord), len(y_coord), len(z_coord), 1)
        observations = observations.transpose(1, 2, 3, 0, 4)
    else:
        raise ValueError(f"Spatial dimension {spatial_dim} not supported")

    tree = ET.parse(xdmf_file)
    root = tree.getroot()
    times = sorted([float(x.attrib['Value']) for x in root.iter('Time')])
    times = np.array(times)
    assert len(times) == observations.shape[-2]

    kwargs = {
        'u': observations,
        'x': x_coord,
        't': times,
    }
    if spatial_dim == 2:
        kwargs['y'] = y_coord
    elif spatial_dim == 3:
        kwargs['y'] = y_coord
        kwargs['z'] = z_coord

    np.savez_compressed(output_path, **kwargs)

def process_navier_stokes_channel(h5_file: Path, xdmf_file: Path, p_file: Path, output_path: Path):
    observations = []
    with h5py.File(h5_file, 'r') as f:
        grid = f['Mesh']['0']['mesh']['geometry'][:]
        for key in sorted(f['VisualisationVector'].keys(), key=int):
            observations.append(f['VisualisationVector'][key][:])
        observations = np.array(observations)

    p_values = []
    with h5py.File(p_file, 'r') as f:
        for key in sorted(f['VisualisationVector'].keys(), key=int):
            p_values.append(f['VisualisationVector'][key][:])
        p_values = np.array(p_values)

    x_coord = sorted(set(grid[:, 0]))
    y_coord = sorted(set(grid[:, 1]))
    observations = observations.reshape(-1, len(y_coord), len(x_coord), 3)
    p_values = p_values.reshape(-1, len(y_coord), len(x_coord), 1)
    # (Nt, Ny, Nx, 3) -> (Nx, Ny, Nt, 3)
    observations = observations.transpose(2, 1, 0, 3)
    p_values = p_values.transpose(2, 1, 0, 3)

    tree = ET.parse(xdmf_file)
    root = tree.getroot()
    times = sorted([float(x.attrib['Value']) for x in root.iter('Time')])
    times = np.array(times)

    kwargs = {
        'u': observations,
        'x': x_coord,
        'y': y_coord,
        't': times,
    }
    np.savez_compressed(output_path, **kwargs)

def process_navier_stokes_cylinder(u_path: Path, grid_path: Path, time_path: Path, output_path: Path):
    u_raw = np.genfromtxt(u_path, delimiter=',')
    grid = np.genfromtxt(grid_path, delimiter=',')
    timesteps = np.genfromtxt(time_path, delimiter=',')

    x_coord = sorted(set(grid[:, 0]))
    y_coord = sorted(set(grid[:, 1]))
    u = u_raw.reshape(len(timesteps), len(x_coord), len(y_coord), 3)
    u = np.transpose(u, (1, 2, 0, 3))

    kwargs = {
        'u': u,
        'x': x_coord,
        'y': y_coord,
        't': timesteps,
    }

    np.savez_compressed(output_path, **kwargs)

def process_burger(h5_file: Path, xdmf_file: Path, output_path: Path):
    observations = []
    with h5py.File(h5_file, 'r') as f:
        grid = f['Mesh']['0']['mesh']['geometry'][:]
        grid = grid[:, 0] # data is 1d
        for key in sorted(f['VisualisationVector'].keys(), key=int):
            observations.append(f['VisualisationVector'][key][:])
        observations = np.array(observations)
        observations = observations.transpose(1, 0, 2)

    tree = ET.parse(xdmf_file)
    root = tree.getroot()
    times = sorted([float(x.attrib['Value']) for x in root.iter('Time')])
    times = np.array(times)

    kwargs = {
        'u': observations,
        'x': grid,
        't': times,
    }
    np.savez_compressed(output_path, **kwargs)

def process_heat_laser(h5_file: Path, xdmf_file: Path, output_path: Path):
    observations = []
    with h5py.File(h5_file, 'r') as f:
        grid = f['Mesh']['0']['mesh']['geometry'][:]
        for key in sorted(f['VisualisationVector'].keys(), key=int):
            observations.append(f['VisualisationVector'][key][:])
        observations = np.array(observations)

    x_coord = sorted(set(grid[:, 0]))
    y_coord = sorted(set(grid[:, 1]))
    z_coord = sorted(set(grid[:, 2]))
    observations = observations.reshape(-1, len(z_coord), len(y_coord), len(x_coord), 1)
    observations = observations.transpose(3, 2, 1, 0, 4)

    tree = ET.parse(xdmf_file)
    root = tree.getroot()
    times = sorted([float(x.attrib['Value']) for x in root.iter('Time')])
    times = np.array(times)

    kwargs = {
        'u': observations,
        'x': x_coord,
        'y': y_coord,
        'z': z_coord,
        't': times,
    }
    np.savez_compressed(output_path, **kwargs)

def process_elasticity(h5_file: Path, xdmf_file: Path, output_path: Path):
    observations = []
    with h5py.File(h5_file, 'r') as f:
        grid = f['Mesh']['0']['mesh']['geometry'][:]
        for key in sorted(f['VisualisationVector'].keys(), key=int):
            observations.append(f['VisualisationVector'][key][:])

    # observations seem to have 125 arrays of shape (4026, 3) and 125 arrays of shape (18000, 9)
    # we only keep 125 arrays of shape (4026, 3)
    observations = np.array(observations[::2]).squeeze()
    observations = observations.transpose(1, 0, 2)

    x_coords = sorted(set(grid[:, 0]))
    y_coords = sorted(set(grid[:, 1]))
    z_coords = sorted(set(grid[:, 2]))
    observations = observations.reshape(len(z_coords), len(y_coords), len(x_coords), -1, 3)
    observations = observations.transpose(2, 1, 0, 3, 4)

    tree = ET.parse(xdmf_file)
    root = tree.getroot()
    times = sorted([float(x.attrib['Value']) for x in root.iter('Time')])
    times = np.array(times)

    kwargs = {
        'u': observations,
        'x': x_coords,
        'y': y_coords,
        'z': z_coords,
        't': times,
    }
    np.savez_compressed(output_path, **kwargs)


if __name__ == "__main__":
    args = parse_args()
    h5_dir = Path(args.h5_dir)
    output_dir = Path(args.output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)

    systems = [
        'heat_soil_uniform_1d_p1',
        'heat_soil_uniform_2d_p1',
        'heat_soil_uniform_1d_p2',
        'heat_soil_uniform_2d_p2',
        'heat_soil_uniform_3d_p1',
        'heat_soil_uniform_3d_p2',
    ]
    for system in systems:
        process_heat_soil(
            h5_file=h5_dir / f'{system}.h5',
            xdmf_file=h5_dir / f'{system}.xdmf',
            output_path=output_dir / f'{system}.npz')

    systems = [
        'navier_stokes_channel_1',
        'navier_stokes_channel_2',
    ]
    for system in systems:
        process_navier_stokes_channel(
            h5_file=h5_dir / f'{system}_u.h5',
            xdmf_file=h5_dir / f'{system}_u.xdmf',
            p_file=h5_dir / f'{system}_p.h5',
            output_path=output_dir / f'{system}.npz')

    process_burger(
        h5_file=h5_dir / 'burgers-1d.h5',
        xdmf_file=h5_dir / 'burgers-1d.xdmf',
        output_path=output_dir / 'burgers-1d.npz'
    )

    heat_laser_file = h5_dir / 'heat3d_laser.h5'
    heat_laser_xdmf = h5_dir / 'heat3d_laser.xdmf'
    process_heat_laser(
        h5_file=heat_laser_file,
        xdmf_file=heat_laser_xdmf,
        output_path=output_dir / 'heat3d_laser.npz'
    )

    process_elasticity(
        h5_file=h5_dir / 'elastodynamics_3d.h5',
        xdmf_file=h5_dir / 'elastodynamics_3d.xdmf',
        output_path=output_dir / 'elastodynamics_3d.npz'
    )

    u_raw = np.genfromtxt(h5_dir / 'ns_cylinder_structured_fenics_velocity_and_pressure.csv', delimiter=',')
    grid = np.genfromtxt(h5_dir / 'ns_cylinder_structured_fenics_mesh.csv', delimiter=',')
    timesteps = np.genfromtxt(h5_dir / 'ns_cylinder_structured_fenics_timesteps.csv', delimiter=',')
    process_navier_stokes_cylinder(
        u_path=h5_dir/'ns_cylinder_structured_fenics_velocity_and_pressure.csv',
        grid_path=h5_dir/'ns_cylinder_structured_fenics_mesh.csv',
        time_path=h5_dir/'ns_cylinder_structured_fenics_timesteps.csv',
        output_path=output_dir / 'ns_cylinder_structured_fenics_mesh.npz'
    )
